{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mpn1ti5Urdsv"
   },
   "source": [
    "# Lecture 13: Hardware Acceleration Implementation\n",
    "\n",
    "In this lecture, we will to walk through backend scafoldings to get us hardware accelerations for Needle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkXPIjVd90z7"
   },
   "source": [
    "**GPU runtime**\n",
    "\n",
    "In this lecture, we are going to make use of C++ and CUDA to build accelerated linear algebra libraries. In order to do so, please make sure you select a runtime type with GPU:\n",
    "\n",
    "$$\n",
    "\\verb|Runtime|\n",
    "\\longrightarrow\n",
    "\\verb|Change runtime type|\n",
    "\\longrightarrow\n",
    "\\verb|Hardware accelerator: GPU|\n",
    "\\longrightarrow\n",
    "\\verb|Save|\n",
    "$$\n",
    "\n",
    "After you started the right runtime, you can run the following command to check if there is a GPU available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VM6IcuZ-kv6",
    "outputId": "9d2a2cd4-e861-477f-b4a4-f47223b3e6cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  2 11:01:29 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 30%   37C    P8    16W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   45C    P8    32W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 39%   36C    P8    15W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXysoqn-vZuF"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "To get started, we can clone the related repo from the github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjEIRTyr8ajf",
    "outputId": "c1e8ec0b-811d-40c0-f56a-6fec190c7907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive\n",
      "/content/drive/MyDrive/10714f22\n",
      "Cloning into 'lecture14'...\n",
      "remote: Enumerating objects: 53, done.\u001b[K\n",
      "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
      "remote: Total 53 (delta 15), reused 50 (delta 12), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (53/53), done.\n"
     ]
    }
   ],
   "source": [
    "# Code to set up the assignment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/\n",
    "!mkdir -p 10714f22\n",
    "%cd /content/drive/MyDrive/10714f22\n",
    "# comment out the following line if you run it for the second time\n",
    "# as you already have a local copy of lecture14\n",
    "# !git clone https://github.com/dlsyscourse/lecture14 \n",
    "!ln -s /content/drive/MyDrive/10714f22/lecture14 /content/needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xe3vClsD9jlq",
    "outputId": "87a092ef-04f2-4610-bd4c-660533864da3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pybind11\n",
      "  Downloading pybind11-2.10.0-py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 5.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: pybind11\n",
      "Successfully installed pybind11-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pybind11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_RrW38i_JNp"
   },
   "source": [
    "### Build project\n",
    "\n",
    "We leverage pybind to build a C++/CUDA library for acceleration. Type make to build the corresponding library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0EdAcB19saK",
    "outputId": "9df25f15-a46e-486a-ebd1-3b15cf8219bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf build python/needle/backend_ndarray/ndarray_backend*.so\n",
      "-- The C compiler identification is GNU 9.4.0\n",
      "-- The CXX compiler identification is GNU 9.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found Python: /home/willyu/anaconda3/envs/10-414/bin/python3.9 (found version \"3.9.13\") found components: Development Interpreter \n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- Found pybind11: /home/willyu/anaconda3/envs/10-414/lib/python3.9/site-packages/pybind11/include (found version \"2.10.0\")\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found CUDA: /usr/local/cuda (found version \"11.4\") \n",
      "-- Found cuda, building cuda backend\n",
      "Wed Nov  2 11:04:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 30%   37C    P8    16W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   44C    P8    23W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 39%   37C    P8    24W / 350W |      5MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "-- Autodetected CUDA architecture(s):  8.6 8.6 8.6\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/willyu/10-414/l13/build\n",
      "make[1]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "make[2]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
      "/home/willyu/10-414/l13/src/ndarray_backend_cuda.cu(99): warning: variable \"gid\" was declared but never referenced\n",
      "\n",
      "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cuda\u001b[0m\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "[ 50%] Built target ndarray_backend_cuda\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cpu\u001b[0m\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cpu.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "[100%] Built target ndarray_backend_cpu\n",
      "make[2]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "make[1]: Leaving directory '/home/willyu/10-414/l13/build'\n"
     ]
    }
   ],
   "source": [
    "#%cd /content/needle\n",
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFxG3p3S1sBq"
   },
   "source": [
    "We can then run the following command to make the path to the package available in local environment as well as `PYTHONPATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bix8OXLuCOKt",
    "outputId": "7ec83f6e-c7db-4bb8-a179-2f73b694cc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=./python:/env/python\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTHONPATH ./python:/env/python\n",
    "import sys\n",
    "sys.path.append(\"./python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBIuE2jc1DaU"
   },
   "source": [
    "## File organization\n",
    "\n",
    "Now click the files panel on the left side. You should be able to see these files\n",
    "\n",
    "Python:\n",
    "- `needle/backend_ndarray/ndarray.py`\n",
    "- `needle/backend_ndarray/ndarray_backend_numpy.py`\n",
    "\n",
    "C++/CUDA\n",
    "- `src/ndarray_backend_cpu.cc`\n",
    "- `src/ndarray_backend_cuda.cu`\n",
    "\n",
    "The main goal of this lecture is to create an accelerated NDArray library. As a result, we do not need to deal with `needle.Tensor` for now and will focus on `backend_ndarray` implementation. \n",
    "\n",
    "After we build up this array library, we can use it to power backend array computations in Needle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1Z8wSsI6PrU"
   },
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N2bm_WB9uF4V"
   },
   "outputs": [],
   "source": [
    "from needle import backend_ndarray as nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZGnTUsKF1x1"
   },
   "source": [
    "We can create a CUDA tensor from the data by specifying the `device` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lwXRXHbnN2-s"
   },
   "outputs": [],
   "source": [
    "x = nd.NDArray([1, 2, 3], device=nd.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aSEJ911pJmkH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuda()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hSjmK60DOFEi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([2. 3. 4.], device=cuda())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZBlbinVMYNhA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([2. 4. 6.], device=cuda())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + x\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.numpy()` returns a **new** CPU tensor instead of modifiying the tensor in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t4UuEs9KAkDR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBMvL6QEBtG7",
    "outputId": "9d5539ec-f4ad-47a5-f4ec-7b89160f573a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuda()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPjNJfJsf_T9"
   },
   "source": [
    "### Key Data Structures\n",
    "\n",
    "Key data structures in `backend_ndarray`\n",
    "\n",
    "- NDArray: the container to hold device specific ndarray\n",
    "- `BackendDevice`: backend device\n",
    "    - `mod` holds the module implementation that implements all functions\n",
    "    - checkout `ndarray_backend_numpy.py` for a python-side reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxKF9dcFhTy3"
   },
   "source": [
    "## GPU execution trace\n",
    "\n",
    "Now, let us take a look at what happens when we execute the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLLzZzuthhBH"
   },
   "outputs": [],
   "source": [
    "x = nd.NDArray([1, 2, 3], device=nd.cuda())\n",
    "y = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9NV0JFESkIe",
    "outputId": "35ac0a8a-dd5e-41bc-ddd0-6f6eb3fc96d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function needle.backend_ndarray.ndarray_backend_cuda.PyCapsule.from_numpy>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device.from_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6vwR3yBRI9F"
   },
   "outputs": [],
   "source": [
    "x = nd.NDArray([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PxoH_UzRMd3",
    "outputId": "e80add43-5a45-4e36-db1c-9db08ec0c24b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function needle.backend_ndarray.ndarray_backend_cuda.PyCapsule.from_numpy>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device.from_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xU5PFJJ-iR7J"
   },
   "source": [
    "Have the following trace:\n",
    "\n",
    "backend_ndarray/ndarray.py\n",
    "- `NDArray.__add__`\n",
    "- `NDArray.ewise_or_scalar`\n",
    "- `ndarray_backend_cpu.cc:ScalarAdd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxAKyM6yjr_R",
    "outputId": "b8ff88fd-aba8-474c-ec17-5399b2c8a1ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4vqb_a4j2O8"
   },
   "source": [
    "Have the following trace:\n",
    "\n",
    "- `NDArray.numpy`\n",
    "- `ndarray_backend_cpu.cc:to_numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMiFJmJVlD6j"
   },
   "source": [
    "### Reading C++/CUDA codes\n",
    "\n",
    "Read\n",
    "- `src/ndarray_backend_cpu.cc`\n",
    "- `src/ndarray_backend_cuda.cu`\n",
    "\n",
    "Optional\n",
    "- `CMakeLists.txt`: this is used to setup the build and likely you do not need to tweak it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEpPbwQKkSkZ"
   },
   "source": [
    "## NDArray\n",
    "\n",
    "Open `python/needle/backend_ndarray/ndarray.py`.\n",
    "\n",
    "An NDArray contains the following fields:\n",
    "- `handle`: the backend handle that build a flat array which stores the data\n",
    "- `shape`: the shape of NDArray\n",
    "- `strides`: the strides that shows how do we access multi-dimensional elements\n",
    "- `offset`: the offset of the first element\n",
    "- `device`: the backend device that backs the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "875DgxFFACqb"
   },
   "source": [
    "### Strided transformation\n",
    "\n",
    "We can leverage the strides and offset to perform transform/slicing with zero copy.\n",
    "\n",
    "- Broadcast: insert $0$ strides\n",
    "- Tranpose: swap the strides\n",
    "- Slice: change the offset and shape \n",
    "\n",
    "For most of the computation, however, we will call `array.compact()` first to get a contiguous and aligned memory before running the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I49fcoiyWYLt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = nd.NDArray([0, 1, 2, 3, 4, 5],\n",
    "               device=nd.cpu_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\verb|y|[i, j]\n",
    "&=\n",
    "\\verb|x|[\\verb|strides|[0] \\times i + \\verb|strides|[1] \\times j] \\\\\n",
    "&=\n",
    "\\verb|x|[3i + \\color{gray}{1}j]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5rNS5MW67XyX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([[0. 1. 2.]\n",
       " [3. 4. 5.]], device=cpu_numpy())"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nd.NDArray.make(shape=(2,3),\n",
    "                    strides=(3,1),\n",
    "                    device=x.device,\n",
    "                    handle=x._handle,\n",
    "                    offset=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oceIop5P7RHW"
   },
   "source": [
    "#### Transpose\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\verb|z|[i, j]\n",
    "&=\n",
    "\\verb|x|[\\verb|strides|^\\mathsf{T}[0] \\times i + \\verb|strides|^\\mathsf{T}[1] \\times j] \\\\\n",
    "&=\n",
    "\\verb|x|[\\color{gray}{1}i + 3j]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "C7zCed7e7B4u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([[0. 3.]\n",
       " [1. 4.]\n",
       " [2. 5.]], device=cpu_numpy())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = nd.NDArray.make(shape=(3,2),\n",
    "                    strides=(1,3),\n",
    "                    device=x.device,\n",
    "                    handle=x._handle,\n",
    "                    offset=0)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\verb|w|[i, j]\n",
    "&=\n",
    "\\verb|x|[\\color{blue}{1} + \\verb|strides|[0] \\times i + \\verb|strides|[1] \\times j] \\\\\n",
    "&=\n",
    "\\verb|x|[\\color{blue}{1} + 3i + \\color{gray}{1}j]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([[1. 2.]\n",
       " [4. 5.]], device=cpu_numpy())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = nd.NDArray.make(shape=(2,2),\n",
    "                    strides=(3,1),\n",
    "                    device=x.device,\n",
    "                    handle=x._handle,\n",
    "                    offset=1)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\verb|b|[i, j, k]\n",
    "&=\n",
    "\\verb|y|[\\verb|strides|[0] \\times i + \\verb|strides|[1] \\times j + \\verb|strides|[2] \\times k] \\\\\n",
    "&=\n",
    "\\verb|y|[3i + \\color{gray}{1}j \\color{gray}{+ 0k}]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N0D4mCqjWh6c",
    "outputId": "9cf3de84-d62b-49bf-95b1-b66cd3ed2aa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDArray([[[0. 0. 0. 0.]\n",
       "  [1. 1. 1. 1.]\n",
       "  [2. 2. 2. 2.]]\n",
       "\n",
       " [[3. 3. 3. 3.]\n",
       "  [4. 4. 4. 4.]\n",
       "  [5. 5. 5. 5.]]], device=cpu_numpy())"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nd.NDArray.make(shape=(2,3,4),\n",
    "                    strides=(3,1,0),\n",
    "                    device=y.device,\n",
    "                    handle=y._handle,\n",
    "                    offset=0)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ONkZbUuj6Dx"
   },
   "source": [
    "## CUDA Acceleration\n",
    "\n",
    "Open `src/ndarray_cuda_backend.cu` and take a look at current implementation of GPU ops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Og8N3iuZiZ4g"
   },
   "source": [
    "### Adding operators\n",
    "\n",
    "- Add an implementation in `ndarray_backend_cuda.cu` and expose it via pybind11\n",
    "- Call into the operator in `ndarray.py`\n",
    "- Write up testcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xV1I7I2lkOJG",
    "outputId": "b292c476-9100-44fd-e909-028028205890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Found pybind11: /home/willyu/anaconda3/envs/10-414/lib/python3.9/site-packages/pybind11/include (found version \"2.10.0\")\n",
      "-- Found cuda, building cuda backend\n",
      "Wed Nov  2 13:26:19 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 30%   40C    P8    23W / 350W |    261MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:41:00.0 Off |                  N/A |\n",
      "| 30%   45C    P8    32W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:61:00.0 Off |                  N/A |\n",
      "| 39%   37C    P8    15W / 350W |      8MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   2748028      C   ...a3/envs/10-414/bin/python      253MiB |\n",
      "|    1   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1410      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "-- Autodetected CUDA architecture(s):  8.6 8.6 8.6\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/willyu/10-414/l13/build\n",
      "make[1]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "make[2]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
      "/home/willyu/10-414/l13/src/ndarray_backend_cuda.cu(99): warning: variable \"gid\" was declared but never referenced\n",
      "\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-39-x86_64-linux-gnu.so\u001b[0m\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "[ 50%] Built target ndarray_backend_cuda\n",
      "make[3]: Entering directory '/home/willyu/10-414/l13/build'\n",
      "make[3]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "[100%] Built target ndarray_backend_cpu\n",
      "make[2]: Leaving directory '/home/willyu/10-414/l13/build'\n",
      "make[1]: Leaving directory '/home/willyu/10-414/l13/build'\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is because `ndarray.py` was imported in the absence of `ewise_mul`. We can either restart the Jupyter kernel or prepare a separate test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YU870vVVZkzg"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'needle.backend_ndarray.ndarray_backend_cuda' has no attribute 'ewise_mul'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m nd\u001b[38;5;241m.\u001b[39mNDArray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], device\u001b[38;5;241m=\u001b[39mnd\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n",
      "File \u001b[0;32m~/10-414/l13/./python/needle/backend_ndarray/ndarray.py:396\u001b[0m, in \u001b[0;36mNDArray.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mewise_or_scalar(\n\u001b[0;32m--> 396\u001b[0m         other, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mewise_mul\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mscalar_mul\n\u001b[1;32m    397\u001b[0m     )\n",
      "File \u001b[0;32m~/10-414/l13/./python/needle/backend_ndarray/ndarray.py:26\u001b[0m, in \u001b[0;36mBackendDevice.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'needle.backend_ndarray.ndarray_backend_cuda' has no attribute 'ewise_mul'"
     ]
    }
   ],
   "source": [
    "x = nd.NDArray([1, 2, 3], device=nd.cuda())\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a separate `.py` script from command line, which initiates a new Python session, eschews the issue. This is **common development practice** in large projects involving Python C++ *foreign function interface* (FFI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "!python3 test/test_mul.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEtbnbvr6Wt7"
   },
   "source": [
    "## Needle `Tensor` backend\n",
    "\n",
    "So far we only played with the `backend_ndarray` (sub)module, which is a self-contained NDArray implementation within Needle.\n",
    "\n",
    "We can connect NDArray back to Needle as backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JeThSA8zAu_v"
   },
   "outputs": [],
   "source": [
    "import needle as ndl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dobDH96Ql8SV"
   },
   "outputs": [],
   "source": [
    "x = ndl.Tensor([1,2,3], device=ndl.cuda(), dtype=\"float32\")\n",
    "y = ndl.Tensor([2,3,5], device=ndl.cuda(), dtype=\"float32\")\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4827VUz3bwvA",
    "outputId": "57cc213a-9003-44ad-c7db-768ae1342a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "needle.backend_ndarray.ndarray.NDArray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z.cached_data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOHZXcb9v+OAhkcV90YcWT/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
